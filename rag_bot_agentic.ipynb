{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import faiss\n",
                "import numpy as np\n",
                "from sentence_transformers import SentenceTransformer\n",
                "import google.generativeai as genai\n",
                "import json"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Load Data\n",
                "file_path = \"database.csv\"\n",
                "df = pd.read_csv(file_path)\n",
                "df = df.dropna(subset=[\"Review\"]).copy()\n",
                "print(f\"Loaded {len(df)} cafes.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Prepare Data\n",
                "def combine_features(row):\n",
                "    features = [f\"{col}: {val}\" for col, val in row.items() if pd.notna(val)]\n",
                "    return \", \".join(features)\n",
                "\n",
                "df[\"combined_info\"] = df.apply(combine_features, axis=1)\n",
                "sentences = df[\"combined_info\"].tolist()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Generate Embeddings\n",
                "print(\"Loading embedding model...\")\n",
                "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
                "embeddings = embed_model.encode(sentences)\n",
                "print(\"Embeddings generated with shape:\", embeddings.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Create FAISS Index\n",
                "dimension = embeddings.shape[1]\n",
                "index = faiss.IndexFlatL2(dimension)\n",
                "index.add(embeddings)\n",
                "print(f\"Added {index.ntotal} vectors to FAISS index.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Setup Gemini\n",
                "# IMPORTANT: Replace with your actual API key from https://aistudio.google.com/app/apikey\n",
                "GOOGLE_API_KEY = \"YOUR_API_KEY_HERE\"\n",
                "genai.configure(api_key=GOOGLE_API_KEY)\n",
                "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. AGENTIC Query Understanding\n",
                "def understand_query(user_query):\n",
                "    \"\"\"Use Gemini to understand what the user wants\"\"\"\n",
                "    \n",
                "    available_cities = df['location'].unique().tolist()\n",
                "    available_columns = df.columns.tolist()\n",
                "    \n",
                "    analysis_prompt = f\"\"\"\n",
                "    Analyze this user query and extract structured information:\n",
                "    \n",
                "    User Query: \"{user_query}\"\n",
                "    \n",
                "    Available cities: {available_cities}\n",
                "    Available columns: {available_columns}\n",
                "    \n",
                "    Return a JSON object with:\n",
                "    {{\n",
                "        \"query_type\": \"recommendation\" or \"count\" or \"filter\" or \"general\",\n",
                "        \"city_filter\": \"city name\" or null,\n",
                "        \"cuisine_filter\": \"cuisine type\" or null,\n",
                "        \"other_filters\": {{\"column\": \"value\"}} or {{}},\n",
                "        \"num_results\": number (5 for recommendations, 100 for counts),\n",
                "        \"search_query\": \"rewritten query for semantic search\"\n",
                "    }}\n",
                "    \n",
                "    Examples:\n",
                "    - \"cafes in Mumbai\" → {{\"query_type\": \"recommendation\", \"city_filter\": \"mumbai\", \"num_results\": 5, \"search_query\": \"best cafes\"}}\n",
                "    - \"how many cafes in Pune?\" → {{\"query_type\": \"count\", \"city_filter\": \"pune\", \"num_results\": 100}}\n",
                "    - \"Italian restaurants\" → {{\"query_type\": \"recommendation\", \"cuisine_filter\": \"Italian\", \"num_results\": 5}}\n",
                "    \n",
                "    Return ONLY the JSON, no explanation.\n",
                "    \"\"\"\n",
                "    \n",
                "    response = model.generate_content(analysis_prompt)\n",
                "    \n",
                "    # Extract JSON from response\n",
                "    try:\n",
                "        text = response.text.strip()\n",
                "        if text.startswith('```'):\n",
                "            text = text.split('```')[1]\n",
                "            if text.startswith('json'):\n",
                "                text = text[4:]\n",
                "        return json.loads(text.strip())\n",
                "    except:\n",
                "        # Fallback\n",
                "        return {\n",
                "            \"query_type\": \"recommendation\",\n",
                "            \"city_filter\": None,\n",
                "            \"num_results\": 5,\n",
                "            \"search_query\": user_query\n",
                "        }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 7. Smart Retrieval Based on Query Understanding\n",
                "def retrieve_cafes(query_analysis):\n",
                "    \"\"\"Retrieve cafes based on the understood query\"\"\"\n",
                "    \n",
                "    # Start with full dataframe\n",
                "    filtered_df = df.copy()\n",
                "    \n",
                "    # Apply filters\n",
                "    if query_analysis.get('city_filter'):\n",
                "        city = query_analysis['city_filter'].lower()\n",
                "        filtered_df = filtered_df[filtered_df['location'].str.lower() == city]\n",
                "    \n",
                "    if query_analysis.get('cuisine_filter'):\n",
                "        cuisine = query_analysis['cuisine_filter']\n",
                "        filtered_df = filtered_df[filtered_df['Cuisine'].str.contains(cuisine, case=False, na=False)]\n",
                "    \n",
                "    # Apply other filters\n",
                "    for col, val in query_analysis.get('other_filters', {}).items():\n",
                "        if col in filtered_df.columns:\n",
                "            filtered_df = filtered_df[filtered_df[col].str.contains(str(val), case=False, na=False)]\n",
                "    \n",
                "    if len(filtered_df) == 0:\n",
                "        return [], query_analysis\n",
                "    \n",
                "    # For counting queries, return all filtered results\n",
                "    if query_analysis['query_type'] == 'count':\n",
                "        return filtered_df.to_dict('records'), query_analysis\n",
                "    \n",
                "    # For recommendations, do semantic search within filtered results\n",
                "    filtered_indices = filtered_df.index.tolist()\n",
                "    filtered_embeddings = embeddings[filtered_indices]\n",
                "    \n",
                "    # Create temp index\n",
                "    temp_index = faiss.IndexFlatL2(dimension)\n",
                "    temp_index.add(filtered_embeddings)\n",
                "    \n",
                "    # Search\n",
                "    search_query = query_analysis.get('search_query', '')\n",
                "    query_vector = embed_model.encode([search_query])\n",
                "    num_results = min(query_analysis['num_results'], len(filtered_df))\n",
                "    distances, indices = temp_index.search(query_vector, num_results)\n",
                "    \n",
                "    results = []\n",
                "    for i in indices[0]:\n",
                "        results.append(filtered_df.iloc[i].to_dict())\n",
                "    \n",
                "    return results, query_analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 8. Agentic RAG Chat Loop\n",
                "def chat_with_agentic_rag():\n",
                "    print(\"\\n☕ Agentic RAG Cafe Bot is ready! Type 'exit' to stop.\\n\")\n",
                "    chat = model.start_chat(history=[])\n",
                "    \n",
                "    # Global context\n",
                "    unique_cities = df['location'].unique().tolist()\n",
                "    total_cafes = len(df)\n",
                "    city_counts = df['location'].value_counts().to_dict()\n",
                "    \n",
                "    global_summary = f\"\"\"DATASET OVERVIEW:\n",
                "    - Total Cafes: {total_cafes}\n",
                "    - Cities: {', '.join(unique_cities)}\n",
                "    - Cafes per City: {city_counts}\n",
                "    \"\"\"\n",
                "    \n",
                "    while True:\n",
                "        user_input = input(\"You: \")\n",
                "        if user_input.lower() in ['exit', 'quit']:\n",
                "            print(\"Chatbot session ended.\")\n",
                "            break\n",
                "        \n",
                "        # Step 1: Understand the query\n",
                "        print(\"[Analyzing query...]\")\n",
                "        query_analysis = understand_query(user_input)\n",
                "        print(f\"[Understood: {query_analysis['query_type']} query]\")\n",
                "        \n",
                "        # Step 2: Retrieve relevant data\n",
                "        retrieved_cafes, analysis = retrieve_cafes(query_analysis)\n",
                "        \n",
                "        if len(retrieved_cafes) == 0:\n",
                "            print(\"Gemini: I couldn't find any cafes matching your criteria.\")\n",
                "            continue\n",
                "        \n",
                "        # Step 3: Generate response\n",
                "        if analysis['query_type'] == 'count':\n",
                "            context_str = f\"Found {len(retrieved_cafes)} cafes matching the criteria.\"\n",
                "        else:\n",
                "            context_str = \"\\n\\n\".join([str(cafe) for cafe in retrieved_cafes[:5]])\n",
                "        \n",
                "        prompt = f\"\"\"\n",
                "        You are a helpful cafe assistant.\n",
                "        \n",
                "        {global_summary}\n",
                "        \n",
                "        Query Type: {analysis['query_type']}\n",
                "        Filters Applied: {analysis}\n",
                "        \n",
                "        RETRIEVED DATA:\n",
                "        {context_str}\n",
                "        \n",
                "        User Question: {user_input}\n",
                "        \n",
                "        Provide a helpful answer based on the retrieved data.\n",
                "        \"\"\"\n",
                "        \n",
                "        try:\n",
                "            response = chat.send_message(prompt)\n",
                "            print(\"Gemini:\", response.text)\n",
                "        except Exception as e:\n",
                "            print(\"Error:\", str(e))\n",
                "            break\n",
                "\n",
                "# Uncomment to run the chatbot\n",
                "# chat_with_agentic_rag()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}